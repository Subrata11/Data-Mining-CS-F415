{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori algorithm works on the principle of Association Rule Mining. Association rule mining is a technique to identify underlying relations between different items. This relationship can be a similarity between items on how frequently they are bought or how similar users bought it.\n",
    "\n",
    "In this labsheet, we will be looking on how the Apriori algorithm works with a python example.\n",
    "\n",
    "## Market Based Analysis\n",
    "\n",
    "It is one of the key techniques used by large retailers to uncover associations between items. They try to find out associations between different items and products that can be sold together, which gives assisting in right product placement. Typically, it figures out what products are being bought together and organizations can place products in a similar manner. Let’s understand this better with an example:\n",
    "\n",
    "People who buy Bread usually buy Butter too. The Marketing teams at retail stores should target customers who buy bread and butter and provide an offer to them so that they buy the third item, like eggs. So if customers buy bread and butter and see a discount or an offer on eggs, they will be encouraged to spend more and buy the eggs. This is what market basket analysis is all about. This is just a small example. So, if you take 10000 items data of your Supermart to a Data Scientist, Just imagine the number of insights you can get. And that is why Association Rule mining is so important.\n",
    "\n",
    "\n",
    "## Apriori Algorithm\n",
    "\n",
    "Association rules can be thought of as an IF-THEN relationship. Suppose item A is being bought by the customer, then the chances of item B being picked by the customer too under the same Transaction ID is found out.\n",
    "\n",
    "There are three major components of the Apriori algorithm:\n",
    "1. Support\n",
    "2. Confidence\n",
    "3. Lift\n",
    "\n",
    "We will explain this concept with the help of an example.\n",
    "\n",
    "Suppose we have a record of 1000 customers transactions and we want to find out support, confidence and lift for milk and diapers. out of 1000 transactions, 120 contains a milk and 150 contains a diaper. out of this 150 transaction where a diaper is purchased 30 contains transaction contains milk as well. we will use this data to calculate support, confidence and lift.\n",
    "\n",
    "### Support\n",
    "\n",
    "Support refers to the popularity of item and can be calculated by finding the number of transactions containing a particular item divided by the total number of transactions.\n",
    "\n",
    "**Support(diaper) = (Transactions containing (diaper))/(Total Transactions)**\n",
    "\n",
    "### Confidence\n",
    "\n",
    "Confidence refers to the likelihood that an item B is also bought if item A is bought. It can be calculated by finding the number of transactions where A and B are bought together, divided by the total number of transactions where A is bought. Mathematically, it can be represented as:\n",
    "\n",
    "**Confidence(A → B) = (Transactions containing both (A and B))/(Transactions containing A)**\n",
    "\n",
    "### Lift\n",
    "\n",
    "Lift refers to the increase in the ratio of the sale of B when A is sold.\n",
    "\n",
    "**Lift(A→B) = (Confidence (A→B))/(Support (B))**\n",
    "\n",
    "\n",
    "Association rule by Lift\n",
    "\n",
    "lift = 1 → There is no association between A and B.\n",
    "\n",
    "lift < 1 → A and B are unlikely to be bought together.\n",
    "\n",
    "lift > 1 → greater the lift greater is the likelihood of buying both products together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this file make sure you have installed mlextend library in anaconda environment.\n",
    "To install it, run command in your anaconda prompt:\n",
    "\n",
    "       conda install -c conda-forge mlxtend "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Preparing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e68c0fecdba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#importing Libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransactionEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrequent_patterns\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapriori\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0massociation_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "#importing Libraries\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori,association_rules\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TransactionEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e8fce54664c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransactionEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0moht_ary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moht\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moht_ary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moht\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TransactionEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Preparing the dataset\n",
    "dataset = [['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n",
    "            \n",
    "            \n",
    "oht = TransactionEncoder()\n",
    "oht_ary = oht.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(oht_ary, columns=oht.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Frequent Itemsets and Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apriori' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1383340ea6b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generating frequent Itemsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfrequent_itemsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapriori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_colnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfrequent_itemsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'apriori' is not defined"
     ]
    }
   ],
   "source": [
    "# Generating frequent Itemsets\n",
    "frequent_itemsets = apriori(df, min_support=0.6, use_colnames=True)\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'association_rules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1e8bcd88048d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generating Rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massociation_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequent_itemsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"confidence\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'association_rules' is not defined"
     ]
    }
   ],
   "source": [
    "# Generating Rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=.8)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Plot graph for rules\n",
    "def draw_graph(rules):\n",
    "    rules_to_show = len(rules)\n",
    "    G1 = nx.DiGraph()\n",
    "\n",
    "    color_map=[]\n",
    "    N = 50\n",
    "    colors = np.random.rand(N)    \n",
    "    strs=['R0', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'R9', 'R10', 'R11']   \n",
    "\n",
    "\n",
    "    for i in range (rules_to_show):      \n",
    "        G1.add_nodes_from([\"R\"+str(i)])\n",
    "\n",
    "\n",
    "        for a in rules.iloc[i]['antecedents']:\n",
    "\n",
    "            G1.add_nodes_from([a])\n",
    "\n",
    "            G1.add_edge(a, \"R\"+str(i), color=colors[i] , weight = 2)\n",
    "\n",
    "        for c in rules.iloc[i]['consequents']:\n",
    "\n",
    "                G1.add_nodes_from([c])\n",
    "\n",
    "                G1.add_edge(\"R\"+str(i), c, color=colors[i],  weight=2)\n",
    "\n",
    "    for node in G1:\n",
    "        found_a_string = False\n",
    "        for item in strs: \n",
    "            if node==item:\n",
    "                found_a_string = True\n",
    "        if found_a_string:\n",
    "            color_map.append('yellow')\n",
    "        else:\n",
    "            color_map.append('green')       \n",
    "\n",
    "\n",
    "\n",
    "    edges = G1.edges()\n",
    "    colors = [G1[u][v]['color'] for u,v in edges]\n",
    "    weights = [G1[u][v]['weight'] for u,v in edges]\n",
    "\n",
    "    pos = nx.spring_layout(G1, k=16, scale=1)\n",
    "    nx.draw(G1, pos, edges=edges, node_color = color_map, edge_color=colors, width=weights, font_size=16, with_labels=False)            \n",
    "\n",
    "    for p in pos:  # raise text positions\n",
    "        pos[p][1] += 0.07\n",
    "    nx.draw_networkx_labels(G1, pos)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e8f2446e364e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_graph\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rules' is not defined"
     ]
    }
   ],
   "source": [
    "draw_graph (rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
